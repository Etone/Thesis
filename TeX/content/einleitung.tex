\chapter{Einleitung}
\label{chap:einleitung}
Die Welt wird immer stärker vernetzt. Durch den Drang, Anwendungen für viele Nutzer zugänglich zu machen besteht der Bedarf an Cloud-Diensten wie \gls{acr-aws}.
Eine dabei immer wieder auftretende Schwierigkeit ist es, die Skalierbarkeit des Services zu gewährleisten. Selbst wenn viele Nutzer zeitgleich auch einen Service zugreifen, darf dieser nicht unter der Last zusammen brechen.

Bis vor einigen Jahren wurde diese Skalierbarkeit durch \glspl{acr-vm} gewährleistet. Doch neben großem Konfigurationsaufwand haben \glspl{acr-vm} auch einen großen Footprint und sind für viele  Anwendungen zu ineffizient. Eine Lösung für dieses Problem stellen Container.

Diese Arbeit untersucht die Möglichkeiten, die Container dem Entwicklungszyklus geben. Um ein grundlegendes Verständnis der Technologie zu vermitteln, werden die verwendeten Techniken hinter Container zu Beginn der Arbeit erklärt und anhand eines praktischen Beispiels näher beleuchtet. Dazu wird ein eigener Prozess in einer Linuxumgebung isoliert und so eine eigene Container-Laufzeitumgebung für diesen geschaffen.

Im Anschluss wird ein historischer Blick auf die Container-Landschaft gegeben und untersucht, wie Docker der erfolgreichste Vertreter dieser Technologie wurde. Dabei wird vor allem auf die Anfänge der Isolierung und Virtualisierung eingegangen und historische Konzepte wie \glspl{acr-cgroup} näher beleuchtet.

Im weiteren Teil der Ausarbeitung werden Vergleiche zwischen verschiedenen aktuell verwendeten Container-Laufzeitumgebungen gezogen und aufgezeigt, wie gut diese auf dem Markt aufgenommen werden. Dabei wird auch ein Blick in verschiedene Container-Orchestrierungsplattformen gegeben und aufgezeigt, welche Plattformen welche Technologien unterstützen.

%Abschluss durch Serverlose Architektur, nur wenn die Zeit reicht